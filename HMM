import numpy as np
from collections import defaultdict

class HiddenMarkovModel:
    def __init__(self, states, observations, start_prob, trans_prob, emit_prob):
        self.states = states
        self.observations = observations
        self.N = len(states)
        self.M = len(observations)
        self.start_prob = np.array([start_prob[s] for s in states])
        self.trans_prob = np.array([[trans_prob[s1][s2] for s2 in states] for s1 in states])
        self.emit_prob = np.array([[emit_prob[s][o] for o in observations] for s in states])

    def forward(self, obs_seq):
        T = len(obs_seq)
        alpha = np.zeros((T, self.N))
        alpha[0] = self.start_prob * self.emit_prob[:, self.observations.index(obs_seq[0])]
        for t in range(1, T):
            for j in range(self.N):
                alpha[t, j] = np.sum(alpha[t-1] * self.trans_prob[:, j]) * self.emit_prob[j, self.observations.index(obs_seq[t])]
        return alpha

    def backward(self, obs_seq):
        T = len(obs_seq)
        beta = np.zeros((T, self.N))
        beta[T-1] = 1
        for t in reversed(range(T-1)):
            for i in range(self.N):
                beta[t, i] = np.sum(self.trans_prob[i, :] * self.emit_prob[:, self.observations.index(obs_seq[t+1])] * beta[t+1])
        return beta

    def viterbi(self, obs_seq):
        T = len(obs_seq)
        delta = np.zeros((T, self.N))
        psi = np.zeros((T, self.N), dtype=int)
        delta[0] = self.start_prob * self.emit_prob[:, self.observations.index(obs_seq[0])]
        for t in range(1, T):
            for j in range(self.N):
                seq_probs = delta[t-1] * self.trans_prob[:, j]
                psi[t, j] = np.argmax(seq_probs)
                delta[t, j] = np.max(seq_probs) * self.emit_prob[j, self.observations.index(obs_seq[t])]
        # Backtrack
        path = np.zeros(T, dtype=int)
        path[T-1] = np.argmax(delta[T-1])
        for t in reversed(range(1, T)):
            path[t-1] = psi[t, path[t]]
        state_path = [self.states[i] for i in path]
        return state_path, delta

    def baum_welch(self, obs_seq, n_iter=10):
        T = len(obs_seq)
        obs_idx = [self.observations.index(o) for o in obs_seq]
        for n in range(n_iter):
            alpha = self.forward(obs_seq)
            beta = self.backward(obs_seq)
            xi = np.zeros((T-1, self.N, self.N))
            gamma = np.zeros((T, self.N))
            for t in range(T-1):
                denom = np.sum(alpha[t] * beta[t])
                for i in range(self.N):
                    numer = alpha[t, i] * self.trans_prob[i, :] * self.emit_prob[:, obs_idx[t+1]] * beta[t+1]
                    xi[t, i, :] = numer / denom
            gamma = np.sum(xi, axis=2)
            # Update start_prob
            self.start_prob = gamma[0] / np.sum(gamma[0])
            # Update trans_prob
            self.trans_prob = np.sum(xi, axis=0) / np.sum(gamma[:-1], axis=0)[:, None]
            # Update emit_prob
            for k in range(self.M):
                mask = np.array(obs_idx) == k
                self.emit_prob[:, k] = np.sum(gamma[mask], axis=0) / np.sum(gamma, axis=0)
        return self

if __name__ == "__main__":
    # Example: Dice roll HMM (fair vs loaded dice)
    states = ['Fair', 'Loaded']
    observations = ['1', '2', '3', '4', '5', '6']
    start_prob = {'Fair': 0.5, 'Loaded': 0.5}
    trans_prob = {
        'Fair': {'Fair': 0.95, 'Loaded': 0.05},
        'Loaded': {'Fair': 0.1, 'Loaded': 0.9}
    }
    emit_prob = {
        'Fair': {o: 1/6 for o in observations},
        'Loaded': {**{str(i): 0.1 for i in range(1,6)}, '6': 0.5}
    }
    hmm = HiddenMarkovModel(states, observations, start_prob, trans_prob, emit_prob)
    obs_seq = ['3', '1', '6', '6', '2', '4', '6', '6', '5', '6']
    print("Observation sequence:", obs_seq)
    print("Viterbi best state path:", hmm.viterbi(obs_seq)[0])
    print("Forward probabilities (alpha):\n", hmm.forward(obs_seq))
    print("Backward probabilities (beta):\n", hmm.backward(obs_seq))
    # Unsupervised learning (Baum-Welch)
    hmm.baum_welch(obs_seq, n_iter=5)
    print("Learned transition probabilities:\n", hmm.trans_prob)
    print("Learned emission probabilities:\n", hmm.emit_prob)
